{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FF_io1ivR3W-",
    "outputId": "acc80038-688b-4f98-9448-34c67c5865d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f702joOHTf2B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M89lGl3t_3DG"
   },
   "source": [
    "## 분석 대상 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mdxMaYCSQds"
   },
   "outputs": [],
   "source": [
    "# train set, test set 분리 및 스케일링 사용 여부 사용자 정의 함수\n",
    "def train_test_split_and_upsample(df_input, scaling):\n",
    "    \n",
    "    df = df_input.copy()\n",
    "    \n",
    "    df = df.astype('category')\n",
    "    df['age'] = df['age'].astype('float64')\n",
    "    df['SitTime'] = df['SitTime'].astype('float64')\n",
    "    df['Total_slp_wk'] = df['Total_slp_wk'].astype('float64')\n",
    "    \n",
    "    df_class_0 = df[df['BMI'] == 0]\n",
    "    df_class_1 = df[df['BMI'] == 1]\n",
    "    \n",
    "    df_class_1_over = df_class_1.sample(df_class_0.shape[0], replace=True, random_state=10)   # 오버샘플링 데이터 만들기 \n",
    "    df_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "    \n",
    "    feature_columns = list(df.columns.difference(['BMI']))   # df의 column들 중 \"BMI\"가 아닌 변수들의 이름을 feature_columns라고 저장\n",
    "    X = df[feature_columns] # X에는 BMI를 제외한 변수들에(독립변수)에 해당하는 데이터를 할당\n",
    "    y = df[['BMI']]         # y에는 BMI 변수에 해당하는 데이터를 할당\n",
    "    \n",
    "    X_res = df_over[feature_columns]    # 오버샘플링한 X 데이터 생성\n",
    "    y_res = df_over[['BMI']]            # 오버샘플링한 y 데이터 생성\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import preprocessing\n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y) \n",
    "    train_x_res, test_x_res, train_y_res, test_y_res = train_test_split(X_res, y_res, test_size = 0.3, random_state = 0, stratify = y_res)\n",
    "    \n",
    "    train_x = train_x.reset_index().iloc[:,1:]\n",
    "    tmp2 = train_x.loc[:,['Total_slp_wk', 'SitTime']]\n",
    "    train_x = train_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "    train_x = pd.concat([train_x, tmp2], axis=1)\n",
    "\n",
    "    test_x = test_x.reset_index().iloc[:,1:]\n",
    "    tmp2 = test_x.loc[:,['Total_slp_wk', 'SitTime']]\n",
    "    test_x = test_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "    test_x = pd.concat([test_x, tmp2], axis=1)\n",
    "\n",
    "    train_y = train_y.reset_index().iloc[:,1:]\n",
    "    \n",
    "    test_y = test_y.reset_index().iloc[:,1:]\n",
    "    \n",
    "    train_x_res = train_x_res.reset_index().iloc[:,1:]\n",
    "    tmp2 = train_x_res.loc[:,['Total_slp_wk', 'SitTime']]\n",
    "    train_x_res = train_x_res.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "    train_x_res = pd.concat([train_x_res, tmp2], axis=1)\n",
    "\n",
    "    train_y_res = train_y_res.reset_index().iloc[:,1:]\n",
    "    \n",
    "    if scaling == True:   # scaling = True일 경우 스케일링(정규화) 적용, scaling = False일 경우 스케일링 적용 X\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp = min_max_scaler.fit_transform(train_x.loc[:,['Total_slp_wk','SitTime']])\n",
    "        temp = pd.DataFrame(temp, columns = ['Total_slp_wk','SitTime'])\n",
    "        train_x = train_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "        train_x = pd.concat([train_x, temp], axis=1)\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp = min_max_scaler.fit_transform(test_x.loc[:,['Total_slp_wk','SitTime']])\n",
    "        temp = pd.DataFrame(temp, columns = ['Total_slp_wk','SitTime'])\n",
    "        test_x = test_x.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "        test_x = pd.concat([test_x, temp], axis=1)\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        temp = min_max_scaler.fit_transform(train_x_res.loc[:,['Total_slp_wk','SitTime']])\n",
    "        temp = pd.DataFrame(temp, columns = ['Total_slp_wk','SitTime'])\n",
    "        train_x_res = train_x_res.drop(['Total_slp_wk', 'SitTime'], axis=1)\n",
    "        train_x_res = pd.concat([train_x_res, temp], axis=1)    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #train = pd.concat([train_x, train_y], axis=1)\n",
    "    #train_res = pd.concat([train_x_res, train_y_res], axis=1)\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y, train_x_res, train_y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucRaUVHK8pMx"
   },
   "outputs": [],
   "source": [
    "# 결측치 행 제거 파일\n",
    "df_all = pd.read_csv('/content/drive/MyDrive/고급데이터마이닝/라스트/df_all.csv')\n",
    "df_all = df_all.iloc[:,1:]\n",
    "df_all\n",
    "\n",
    "# 남녀 데이터 생성\n",
    "df_all_b = df_all.loc[df_all[\"sex\"]==1,:]\n",
    "df_all_g = df_all.loc[df_all[\"sex\"]==2,:]\n",
    "df_all_b = df_all_b.drop('sex', axis = 1)\n",
    "df_all_g = df_all_g.drop('sex', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OZYBll0TVgA",
    "outputId": "e7a5d2d1-5153-4a23-ab08-c74192dfc191"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    41623\n",
       "1.0     7061\n",
       "Name: BMI, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"BMI\"].value_counts()   # 남/녀 통합 데이터셋에서 BMI 분포 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyMOBl34v9FN",
    "outputId": "a9b7a248-ba61-4318-b81a-888b8eb08dd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    19094\n",
       "1.0     4765\n",
       "Name: BMI, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_b[\"BMI\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvoYMPgQwAxJ",
    "outputId": "c7738c58-a0fb-4c71-b960-113f73e64891"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    22529\n",
       "1.0     2296\n",
       "Name: BMI, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_g[\"BMI\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ms61bxGXTMNF",
    "outputId": "c61fbece-e409-4721-d315-47e432118bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48684 entries, 0 to 48683\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sex           48684 non-null  float64\n",
      " 1   age           48684 non-null  float64\n",
      " 2   D_1_1         48684 non-null  float64\n",
      " 3   BP1           48684 non-null  float64\n",
      " 4   BO1           48684 non-null  float64\n",
      " 5   BE5_1         48684 non-null  float64\n",
      " 6   BP5           48684 non-null  float64\n",
      " 7   BMI           48684 non-null  float64\n",
      " 8   Total_slp_wk  48684 non-null  float64\n",
      " 9   SitTime       48684 non-null  float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgJTPmbFS88f"
   },
   "outputs": [],
   "source": [
    "#df_all, df_all_b, df_all_g를 넣으면 각 데이터에 대해서 트레이닝 세트, 테스트 세트, 오버샘플링 적용된 트레이닝 세트 출력\n",
    "tmp = train_test_split_and_upsample(df_all_g, scaling=False) \n",
    "train_x = tmp[0]\n",
    "train_y = tmp[2]\n",
    "test_x = tmp[1]\n",
    "test_y = tmp[3]\n",
    "train_x_res = tmp[4]\n",
    "train_y_res = tmp[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h866p2Q0ZXxC"
   },
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hh2HEguVTSp2"
   },
   "outputs": [],
   "source": [
    "# Performance Measure 출력 함수 만들기\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    F2_Score = (5 * Recall * Precision) / (Recall + 4*Precision) # Recall을 Precision보다 2배 중요하게 생각하여 F2 Score 사용\n",
    "    \n",
    "    print(\"Accuracy: \", Accuracy) \n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"Specificity: \", Specificity)\n",
    "    print(\"F1_Score: \", F1_Score)\n",
    "    print(\"F2_Score: \", F2_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0OaVh21NAuU"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GAU8zksdjWW",
    "outputId": "e6f73a7e-8940-4fc7-80b6-3b73f87d0024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kmeans__n_clusters': 102}\n",
      "0.5575579770885722\n"
     ]
    }
   ],
   "source": [
    "#K-평균 군집을 사용한 전처리 ==> 로지스틱 회귀\n",
    "# 이 블록은 K-평균에서의 최적의 K값 찾는 것. \n",
    "\n",
    "param_grid = dict(kmeans__n_clusters = range(95,105+1))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                     (\"kmeans\", KMeans()),  # \n",
    "                     (\"log_reg\", LogisticRegression(max_iter=15000)),     \n",
    "])\n",
    "\n",
    "grid_clf = GridSearchCV(pipeline, param_grid)\n",
    "grid_clf.fit(train_x_res, train_y_res.values.ravel())  # A column-vector y was passed when a 1d array was expected라는 에러가 떠서 .values.ravel() 이용해서 column vector를 1d array로 형태 변환해줌\n",
    "print(grid_clf.best_params_)\n",
    "print(grid_clf.score(test_x, test_y.values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzXxnHJAiqeA"
   },
   "source": [
    "-데이터별 최적 K값 찾은 결과\n",
    "*   df_all 오버샘플링 안 한 거 최적 kmeans__n_clusters: 2\n",
    "*   df_all_b 오버샘플링 안 한 거 최적 kmeans__n_clusters: 2\n",
    "*   df_all_g 오버샘플링 안 한 거 최적 kmeans__n_clusters: 2\n",
    "*   df_all 오버샘플링 한 거 최적 kmeans__n_clusters: 122\n",
    "*   df_all_b 오버샘플링 한 거 최적 kmeans__n_clusters: 102\n",
    "*   df_all_g 오버샘플링 한 거 최적 kmeans__n_clusters: 140\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c46gd4qPqkjl"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIGKq03IIJlI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "591YZ4u0c15P",
    "outputId": "d349f1f5-b259-4135-f5e6-646e1fe3e6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters : {'C': 1, 'penalty': 'l1'}\n",
      "[[6636  123]\n",
      " [ 425  264]]\n",
      "Accuracy:  0.9264232008592911\n",
      "Precision:  0.6821705426356589\n",
      "Recall:  0.38316400580551524\n",
      "Specificity:  0.9818020417221482\n",
      "F1_Score:  0.4907063197026022\n",
      "F2_Score:  0.4199809099586382\n",
      "None\n",
      "AUC:  0.6824830237638317\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# K Means 전처리하지 않고 그냥 그리드 서치 적용 및 l1 norm, l2 norm\n",
    "\n",
    "# 파라메터 후보\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# 그리드 서치 진행\n",
    "grid_search = GridSearchCV(LogisticRegression(solver='liblinear', random_state = 42), param_grid, cv= 2 )        \n",
    "\n",
    "grid_search.fit(train_x, train_y.values.ravel())\n",
    "grid_search.score(test_x, test_y.values.ravel())\n",
    "print(\"best parameters : {}\".format(grid_search.best_params_))\n",
    "        \n",
    "predicted = grid_search.predict(test_x)\n",
    "print(confusion_matrix(test_y.values.ravel(), predicted))\n",
    "print(model_evaluation(test_y.values.ravel(), predicted))\n",
    "print(\"AUC: \", roc_auc_score(test_y.values.ravel(), np.round(predicted,0)))\n",
    "\n",
    "print('='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WDZKN-6kCCd",
    "outputId": "c96e4362-bda0-4a2c-c359-011a0ed69588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters : {'C': 1, 'l1_ratio': 0.3}\n",
      "[[6688   71]\n",
      " [ 602   87]]\n",
      "Accuracy:  0.909640171858217\n",
      "Precision:  0.5506329113924051\n",
      "Recall:  0.1262699564586357\n",
      "Specificity:  0.9894954874981506\n",
      "F1_Score:  0.20543093270366\n",
      "F2_Score:  0.14927934111187371\n",
      "None\n",
      "AUC:  0.5578827219783932\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# K Means 전처리하지 않고 그냥 그리드 서치 적용 및 ElasticNet 사용 시\n",
    "\n",
    "# 파라메터 후보\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10], 'l1_ratio' : [0.3, 0.6, 0.9]}\n",
    "\n",
    "# 그리드 서치 진행\n",
    "grid_search = GridSearchCV(LogisticRegression(solver='saga', random_state = 42,  max_iter = 5000, penalty= 'elasticnet'), param_grid, cv= 2)        \n",
    "\n",
    "grid_search.fit(train_x, train_y.values.ravel())\n",
    "grid_search.score(test_x, test_y.values.ravel())\n",
    "print(\"best parameters : {}\".format(grid_search.best_params_))\n",
    "        \n",
    "predicted = grid_search.predict(test_x)\n",
    "print(confusion_matrix(test_y.values.ravel(), predicted))\n",
    "print(model_evaluation(test_y.values.ravel(), predicted))\n",
    "print(\"AUC: \", roc_auc_score(test_y.values.ravel(), np.round(predicted,0)))\n",
    "\n",
    "#print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "print('='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjLCrzpGPsSP"
   },
   "source": [
    "-데이터별 최적 K값 찾은 결과\n",
    "*   df_all 오버샘플링 안 한 거 최적 kmeans__n_clusters: 2\n",
    "*   df_all_b 오버샘플링 안 한 거 최적 kmeans__n_clusters: 2\n",
    "*   df_all_g 오버샘플링 안 한 거 최적 kmeans__n_clusters: 2\n",
    "*   df_all 오버샘플링 한 거 최적 kmeans__n_clusters: 122\n",
    "*   df_all_b 오버샘플링 한 거 최적 kmeans__n_clusters: 102\n",
    "*   df_all_g 오버샘플링 한 거 최적 kmeans__n_clusters: 140\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fgtm2TGqgqMX"
   },
   "outputs": [],
   "source": [
    "# K Means 전처리 후 그리드 서치 적용 및 l1 norm, l2 norm 사용 시\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'log_reg__C': [0.01, 0.1, 1, 10],\n",
    "    'log_reg__penalty' : ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                     (\"kmeans\", KMeans(n_clusters= 122 )),  # \n",
    "                     (\"log_reg\", LogisticRegression(solver='liblinear', max_iter = 20000)),     # 이 때 logistic Regression 안에 파라미터 넣던가 아니면 LogistricRegression 대신 GridSearCV를 쓰는 것도 시도해보기 \n",
    "])\n",
    "\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid_clf.fit(train_x_res, train_y_res.values.ravel())  # A column-vector y was passed when a 1d array was expected라는 에러가 떠서 .values.ravel() 이용해서 column vector를 1d array로 형태 변환해줌\n",
    "print(\"best parameters : \", grid_clf.best_params_)\n",
    "print(\"Grid Search Score: \", grid_clf.score(test_x, test_y.values.ravel()))\n",
    "\n",
    "predicted = grid_clf.predict(test_x)\n",
    "print(confusion_matrix(test_y.values.ravel(), predicted))\n",
    "print(model_evaluation(test_y.values.ravel(), predicted))\n",
    "print(\"AUC: \", roc_auc_score(test_y.values.ravel(), np.round(predicted,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P93Zi3A-jZIL",
    "outputId": "879e1f35-8ca8-4847-c3e5-60a32f25d71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters :  {'log_reg__C': 0.01, 'log_reg__l1_ratio': 0.3}\n",
      "Grid Search Score:  0.8002235261246158\n",
      "[[5728    0]\n",
      " [1430    0]]\n",
      "Accuracy:  0.8002235261246158\n",
      "Precision:  nan\n",
      "Recall:  0.0\n",
      "Specificity:  1.0\n",
      "F1_Score:  nan\n",
      "F2_Score:  nan\n",
      "None\n",
      "AUC:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# K Means 전처리 후 그리드 서치 적용 및 ElasticNet 사용 시\n",
    "\n",
    "param_grid = {\n",
    "    'log_reg__C': [ 0.01, 0.1, 1, 10],\n",
    "    'log_reg__l1_ratio' : [0.3, 0.6, 0.9],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                     (\"kmeans\", KMeans(n_clusters= 2 )),  # \n",
    "                     (\"log_reg\", LogisticRegression(solver='saga', penalty = 'elasticnet', max_iter = 20000)),     # 이 때 logistic Regression 안에 파라미터 넣던가 아니면 LogistricRegression 대신 GridSearCV를 쓰는 것도 시도해보기 \n",
    "])\n",
    "\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "grid_clf.fit(train_x_res, train_y_res.values.ravel())  # A column-vector y was passed when a 1d array was expected라는 에러가 떠서 .values.ravel() 이용해서 column vector를 1d array로 형태 변환해줌\n",
    "print(\"best parameters : \", grid_clf.best_params_)\n",
    "print(\"Grid Search Score: \", grid_clf.score(test_x, test_y.values.ravel()))\n",
    "\n",
    "predicted = grid_clf.predict(test_x)\n",
    "print(confusion_matrix(test_y, predicted))\n",
    "print(model_evaluation(test_y, predicted))\n",
    "print(\"AUC: \", roc_auc_score(test_y, np.round(predicted,0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESd8sGCHfho_"
   },
   "source": [
    "## 위에서 찾은 best_params_ 사용해서 변수 중요도 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QIX_vy2fd48",
    "outputId": "6020d46a-cbdb-44d4-d8e8-06cbb32777ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear', random_state = 42)\n",
    "logreg.fit(train_x,train_y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4CEGgafRRZc",
    "outputId": "defd38c2-7f26-4f43-b4cb-ebb682960dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BE5_1': 0.02908344613275947,\n",
       " 'BO1': 2.713225501609422,\n",
       " 'BP1': 0.06770945440741381,\n",
       " 'BP5': -0.0005109535202078197,\n",
       " 'D_1_1': 0.019592490615152683,\n",
       " 'SitTime': 4.7209447552714596e-05,\n",
       " 'Total_slp_wk': 0.0007934749065760172,\n",
       " 'age': 0.1625972019460859}"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀계수 확인\n",
    "coef_dict = {}\n",
    "for coef, feat in zip(logreg.coef_[0,:],train_x.columns):\n",
    "    coef_dict[feat] = coef\n",
    "\n",
    "coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMkVgCrzbNl4",
    "outputId": "7967b9f7-8f2e-4ebb-b8f8-1133d2b4b6e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    BMI   R-squared:                       0.165\n",
      "Model:                            OLS   Adj. R-squared:                  0.165\n",
      "Method:                 Least Squares   F-statistic:                     429.5\n",
      "Date:                Sat, 28 Nov 2020   Prob (F-statistic):               0.00\n",
      "Time:                        09:28:25   Log-Likelihood:                -1560.1\n",
      "No. Observations:               17377   AIC:                             3138.\n",
      "Df Residuals:                   17368   BIC:                             3208.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.5319      0.028    -18.759      0.000      -0.587      -0.476\n",
      "BE5_1            0.0006      0.002      0.367      0.713      -0.003       0.004\n",
      "BO1              0.1318      0.002     56.631      0.000       0.127       0.136\n",
      "BP1             -0.0025      0.003     -0.930      0.353      -0.008       0.003\n",
      "BP5             -0.0013      0.005     -0.272      0.786      -0.011       0.008\n",
      "D_1_1            0.0104      0.003      4.107      0.000       0.005       0.015\n",
      "age              0.0097      0.001      7.550      0.000       0.007       0.012\n",
      "Total_slp_wk  9.601e-05    2.7e-05      3.556      0.000    4.31e-05       0.000\n",
      "SitTime       2.892e-06   8.24e-06      0.351      0.726   -1.33e-05     1.9e-05\n",
      "==============================================================================\n",
      "Omnibus:                     6844.404   Durbin-Watson:                   1.980\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22321.675\n",
      "Skew:                           2.082   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.672   Cond. No.                     1.09e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수 확인 + sklearn에서는 회귀계수를 검정하는 방법이 아직 나오지 않았기 때문에 statsmodels 패키지를 이용하여 설명변수의 p-value만 참고하기\n",
    "# 단 이 코드의 결과는 선형 회귀분석 함수 (OLS)를 이용한 것이기 때문에 회귀계수는 참고하지 않고 p-value만 확인하는 용도로 사용. \n",
    "# 참고 사이트 : https://qastack.kr/programming/27928275/find-p-value-significance-in-scikit-learn-linearregression\n",
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(train_x)\n",
    "model = sm.OLS(train_y, X2)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s41maL57o8pM"
   },
   "outputs": [],
   "source": [
    "df_all = df_all.drop(['Total_slp_wd_standard','SitTime_standard','Total_slp_wd_scaled','SitTime_scaled'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "u_OeoId9oJqz",
    "outputId": "0799412a-63e8-4748-fb9d-522d6f315772"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIF Factor</th>\n",
       "      <td>207.395</td>\n",
       "      <td>1.27953</td>\n",
       "      <td>1.24622</td>\n",
       "      <td>1.16943</td>\n",
       "      <td>1.31023</td>\n",
       "      <td>1.36157</td>\n",
       "      <td>1.16968</td>\n",
       "      <td>1.20655</td>\n",
       "      <td>1.38648</td>\n",
       "      <td>1.29606</td>\n",
       "      <td>1.08284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <td>const</td>\n",
       "      <td>sex</td>\n",
       "      <td>age</td>\n",
       "      <td>D_1_1</td>\n",
       "      <td>BP1</td>\n",
       "      <td>BO1</td>\n",
       "      <td>BE5_1</td>\n",
       "      <td>BP5</td>\n",
       "      <td>BMI</td>\n",
       "      <td>Total_slp_wd</td>\n",
       "      <td>SitTime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0        1        2   ...       8             9        10\n",
       "VIF Factor  207.395  1.27953  1.24622  ...  1.38648       1.29606  1.08284\n",
       "features      const      sex      age  ...      BMI  Total_slp_wd  SitTime\n",
       "\n",
       "[2 rows x 11 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다중 공선성 확인\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "df_all = add_constant(df_all)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(\n",
    "    df_all.values, i) for i in range(df_all.shape[1])]\n",
    "vif[\"features\"] = df_all.columns\n",
    "vif.T"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vaWLgDcdRveG"
   ],
   "name": "Logistic Regression_Final_Report.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
