{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#데이터 불러오기\n",
    "\n",
    "df_delete = pd.read_csv('dataset/delete_null.csv')\n",
    "df_mean = pd.read_csv('dataset/mean_null.csv')\n",
    "df_mode = pd.read_csv('dataset/mode_null.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delete.dropna(inplace=True)\n",
    "df_delete = df_delete.iloc[:,:10]\n",
    "df_delete.astype('category')\n",
    "df_delete['SitTime'] = df_delete['SitTime'].astype('float64')\n",
    "df_delete['Total_slp_wd'] = df_delete['Total_slp_wd'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = list(df_delete.columns.difference(['BMI']))\n",
    "X = df_delete[feature_columns]\n",
    "y = df_delete[['BMI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train, test 나누기\n",
    "# train set은 업샘플링을 위해 다시 사용 되며, est set은 마지막에 모델 평가에 사용\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 0, stratify = y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.concat([train_x,train_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    888\n",
       "0.0    888\n",
       "Name: BMI, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0 = train_x[train_x['BMI'] == 0]\n",
    "df_class_1 = train_x[train_x['BMI'] == 1]\n",
    "\n",
    "df_class_1_over = df_class_1.sample(df_class_0.shape[0], replace=True, random_state=10)\n",
    "df_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = df_over[feature_columns]\n",
    "y_res = df_over[['BMI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling한 데이터에서 test set 나누기\n",
    "train_x_res, test_x_res, train_y_res, test_y_res = train_test_split(X_res, y_res, test_size = 0.3, random_state = 0, stratify = y_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 설명\n",
    "\n",
    "1. 업샘플링 데이터 (train_x_res, train_y_res)\n",
    "2. 업샘플링 데이터2 for valid (test_x_res, test_y_res)\n",
    "3. 실제 test 데이터 for Evaluation (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_rest(df):\n",
    "    df = df.reset_index().iloc[:,1:]\n",
    "    return df\n",
    "\n",
    "for i in [train_x, train_x_res, train_y_res]:\n",
    "    index_rest(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlagy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(train_y_res)\n",
    "train_y_res = encoder.transform(train_y_res)\n",
    "\n",
    "encoder.fit(test_y_res)\n",
    "test_y_res = encoder.transform(test_y_res)\n",
    "\n",
    "encoder.fit(test_y)\n",
    "test_y = encoder.transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout,Embedding, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,input_dim = X_train.shape[1], kernel_initializer= 'he_normal', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Dense(512,kernel_initializer='he_normal',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(128,kernel_initializer='he_normal',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(128,kernel_initializer='he_normal',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(128,kernel_initializer='he_normal',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.75))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, restore_best_weights = True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.3289 - accuracy: 0.4851 - val_loss: 0.6898 - val_accuracy: 0.5441\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2804 - accuracy: 0.5149 - val_loss: 0.7117 - val_accuracy: 0.4991\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2973 - accuracy: 0.5076 - val_loss: 0.7085 - val_accuracy: 0.5009\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.3016 - accuracy: 0.4722 - val_loss: 0.7091 - val_accuracy: 0.5009\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2705 - accuracy: 0.4835 - val_loss: 0.7068 - val_accuracy: 0.5009\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1609 - accuracy: 0.5181 - val_loss: 0.7054 - val_accuracy: 0.5009\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2076 - accuracy: 0.4907 - val_loss: 0.7008 - val_accuracy: 0.5009\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.2272 - accuracy: 0.5084 - val_loss: 0.6984 - val_accuracy: 0.5009\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1736 - accuracy: 0.5141 - val_loss: 0.6976 - val_accuracy: 0.5009\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1344 - accuracy: 0.5068 - val_loss: 0.6976 - val_accuracy: 0.5009\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1048 - accuracy: 0.5093 - val_loss: 0.6969 - val_accuracy: 0.5009\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1541 - accuracy: 0.4940 - val_loss: 0.6971 - val_accuracy: 0.5009\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1455 - accuracy: 0.5084 - val_loss: 0.6968 - val_accuracy: 0.5009\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1643 - accuracy: 0.4747 - val_loss: 0.6960 - val_accuracy: 0.5009\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.1138 - accuracy: 0.4940 - val_loss: 0.6953 - val_accuracy: 0.5009\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.9956 - accuracy: 0.5286 - val_loss: 0.6945 - val_accuracy: 0.5009\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 1.0537 - accuracy: 0.5173 - val_loss: 0.6946 - val_accuracy: 0.5009\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 1.0852 - accuracy: 0.4690 - val_loss: 0.6949 - val_accuracy: 0.5009\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.9758 - accuracy: 0.5093 - val_loss: 0.6951 - val_accuracy: 0.5009\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.9840 - accuracy: 0.4980 - val_loss: 0.6957 - val_accuracy: 0.5009\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.9977 - accuracy: 0.4980 - val_loss: 0.6968 - val_accuracy: 0.5009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x241a0a71760>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(train_x_res.astype(float)), train_y_res, epochs=100, validation_data = (np.array(test_x_res.astype(float)), test_y_res), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5231788079470199\n",
      "Precision:  0.1643192488262911\n",
      "Recall:  0.4794520547945205\n",
      "Specificity:  0.531578947368421\n",
      "F1-Score:  0.24475524475524477\n",
      "F2-Score:  0.3465346534653465\n",
      "auc score:  0.5055155010814707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def model_evaluation(label, predict):\n",
    "    cf_matrix = confusion_matrix(label, predict)\n",
    "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
    "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
    "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
    "    Specificity = cf_matrix[0][0] / (cf_matrix[0][0] + cf_matrix[0][1])\n",
    "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    F2_Score = (5 * Recall * Precision) / (Recall + 4*Precision)\n",
    "    \n",
    "    print(\"Accuracy: \", Accuracy)\n",
    "    print(\"Precision: \", Precision)\n",
    "    print(\"Recall: \", Recall)\n",
    "    print(\"Specificity: \", Specificity)\n",
    "    print(\"F1-Score: \", F1_Score)\n",
    "    print(\"F2-Score: \", F2_Score)\n",
    "    print(\"auc score: \" , roc_auc_score(label, np.round(predict,0)))\n",
    "    \n",
    "model_evaluation(test_y, np.round(y_train_pred,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
